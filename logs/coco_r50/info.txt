[01/12 14:24:45.733]: git:
  sha: N/A, status: clean, branch: N/A

[01/12 14:24:45.733]: Command: /media/test/run/ED-Pose-master-6points-rtdetr-aifi-src-imploss-att-CLOA (3rd copy)/main.py --output_dir logs/coco_r50 -c config/edpose.cfg.py --options batch_size=2 epochs=60 lr_drop=55 num_body_points=6 backbone=resnet50 --dataset_file=coco
[01/12 14:24:45.734]: Full config saved to logs/coco_r50/config_args_all.json
[01/12 14:24:45.734]: world size: 1
[01/12 14:24:45.734]: rank: 0
[01/12 14:24:45.734]: local_rank: 0
[01/12 14:24:45.734]: args: Namespace(config_file='config/edpose.cfg.py', options={'batch_size': 2, 'epochs': 60, 'lr_drop': 55, 'num_body_points': 6, 'backbone': 'resnet50'}, dataset_file='coco', coco_path='/media/test/run/ED-Pose-master-6points/coco', remove_difficult=False, fix_size=False, output_dir='logs/coco_r50', note='', device='cuda', seed=42, resume='', pretrain_model_path=None, finetune_ignore=None, start_epoch=0, eval=False, num_workers=0, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=2, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=2, weight_decay=0.0001, epochs=60, lr_drop=55, save_checkpoint_interval=100, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='edpose', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, random_refpoints_xy=False, fix_refpoints_hw=-1, dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, dln_xy_noise=0.2, dln_hw_noise=0.2, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, rm_detach=None, num_select=50, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, set_cost_keypoints=10, set_cost_kpvis=0.0, set_cost_oks=4.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, keypoints_loss_coef=14, oks_loss_coef=4.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, rm_self_attn_layers=None, indices_idx_list=[1, 2, 3, 4, 5, 6, 7], decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=False, dn_label_coef=0.3, dn_bbox_coef=0.5, dn_batch_gt_fuse=False, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_labelbook_size=100, match_unstable_error=False, use_ema=True, ema_decay=0.9997, ema_epoch=0, cls_no_bias=False, num_body_points=6, num_group=100, num_box_decoder_layers=2, no_mmpose_keypoint_evaluator=True, strong_aug=False)

[01/12 14:24:46.840]: number of params:53089445
[01/12 14:24:46.842]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 12,
  "transformer.decoder.keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_projj.0.0.weight": 65536,
  "input_projj.0.1.weight": 256,
  "input_projj.0.1.bias": 256,
  "input_projj.1.0.weight": 65536,
  "input_projj.1.1.weight": 256,
  "input_projj.1.1.bias": 256,
  "input_projj.2.0.weight": 65536,
  "input_projj.2.1.weight": 256,
  "input_projj.2.1.bias": 256,
  "mlca.conv_bn_relu_prm_1.conv.weight": 589824,
  "mlca.conv_bn_relu_prm_1.conv.bias": 256,
  "mlca.conv_bn_relu_prm_1.bn.weight": 256,
  "mlca.conv_bn_relu_prm_1.bn.bias": 256,
  "mlca.conv_bn_relu_prm_2_1.conv.weight": 65536,
  "mlca.conv_bn_relu_prm_2_1.conv.bias": 256,
  "mlca.conv_bn_relu_prm_2_1.bn.weight": 256,
  "mlca.conv_bn_relu_prm_2_1.bn.bias": 256,
  "mlca.conv_bn_relu_prm_2_2.conv.weight": 65536,
  "mlca.conv_bn_relu_prm_2_2.conv.bias": 256,
  "mlca.conv_bn_relu_prm_2_2.bn.weight": 256,
  "mlca.conv_bn_relu_prm_2_2.bn.bias": 256,
  "mlca.conv_bn_relu_prm_3_1.conv.weight": 65536,
  "mlca.conv_bn_relu_prm_3_1.conv.bias": 256,
  "mlca.conv_bn_relu_prm_3_1.bn.weight": 256,
  "mlca.conv_bn_relu_prm_3_1.bn.bias": 256,
  "mlca.conv_bn_relu_prm_3_2.conv.weight": 20736,
  "mlca.conv_bn_relu_prm_3_2.conv.bias": 256,
  "mlca.conv_bn_relu_prm_3_2.bn.weight": 256,
  "mlca.conv_bn_relu_prm_3_2.bn.bias": 256,
  "mlca.ca.ca.fc0.weight": 4096,
  "mlca.ca.ca.fc0.bias": 16,
  "mlca.ca.ca.bn0.weight": 16,
  "mlca.ca.ca.bn0.bias": 16,
  "mlca.ca.ca.fc1.weight": 256,
  "mlca.ca.ca.fc1.bias": 16,
  "mlca.ca.ca.bn1.weight": 16,
  "mlca.ca.ca.bn1.bias": 16,
  "mlca.ca.ca.fc2.weight": 256,
  "mlca.ca.ca.fc2.bias": 16,
  "mlca.ca.ca.bn2.weight": 16,
  "mlca.ca.ca.bn2.bias": 16,
  "mlca.ca.ca.last_fc.weight": 4096,
  "mlca.ca.ca.last_fc.bias": 256,
  "mlca.sa.sa.conv_reduce1.weight": 4096,
  "mlca.sa.sa.conv_reduce1.bias": 16,
  "mlca.sa.sa.bn_reduce1.weight": 16,
  "mlca.sa.sa.bn_reduce1.bias": 16,
  "mlca.sa.sa.conv_0.weight": 2304,
  "mlca.sa.sa.conv_0.bias": 16,
  "mlca.sa.sa.bn_0.weight": 16,
  "mlca.sa.sa.bn_0.bias": 16,
  "mlca.sa.sa.conv_1.weight": 2304,
  "mlca.sa.sa.conv_1.bias": 16,
  "mlca.sa.sa.bn_1.weight": 16,
  "mlca.sa.sa.bn_1.bias": 16,
  "mlca.sa.sa.conv_2.weight": 2304,
  "mlca.sa.sa.conv_2.bias": 16,
  "mlca.sa.sa.bn_2.weight": 16,
  "mlca.sa.sa.bn_2.bias": 16,
  "mlca.sa.sa.last_conv.weight": 16,
  "mlca.sa.sa.last_conv.bias": 1,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "AIFI.ma.in_proj_weight": 196608,
  "AIFI.ma.in_proj_bias": 768,
  "AIFI.ma.out_proj.weight": 65536,
  "AIFI.ma.out_proj.bias": 256,
  "AIFI.fc1.weight": 131072,
  "AIFI.fc1.bias": 512,
  "AIFI.fc2.weight": 131072,
  "AIFI.fc2.bias": 256,
  "AIFI.norm1.weight": 256,
  "AIFI.norm1.bias": 256,
  "AIFI.norm2.weight": 256,
  "AIFI.norm2.bias": 256,
  "Repc3.cv1.conv.weight": 131072,
  "Repc3.cv1.bn.weight": 256,
  "Repc3.cv1.bn.bias": 256,
  "Repc3.cv2.conv.weight": 131072,
  "Repc3.cv2.bn.weight": 256,
  "Repc3.cv2.bn.bias": 256,
  "Repc3.m.0.conv1.conv.weight": 589824,
  "Repc3.m.0.conv1.bn.weight": 256,
  "Repc3.m.0.conv1.bn.bias": 256,
  "Repc3.m.0.conv2.conv.weight": 65536,
  "Repc3.m.0.conv2.bn.weight": 256,
  "Repc3.m.0.conv2.bn.bias": 256,
  "Repc3.m.1.conv1.conv.weight": 589824,
  "Repc3.m.1.conv1.bn.weight": 256,
  "Repc3.m.1.conv1.bn.bias": 256,
  "Repc3.m.1.conv2.conv.weight": 65536,
  "Repc3.m.1.conv2.bn.weight": 256,
  "Repc3.m.1.conv2.bn.bias": 256,
  "Repc3.m.2.conv1.conv.weight": 589824,
  "Repc3.m.2.conv1.bn.weight": 256,
  "Repc3.m.2.conv1.bn.bias": 256,
  "Repc3.m.2.conv2.conv.weight": 65536,
  "Repc3.m.2.conv2.bn.weight": 256,
  "Repc3.m.2.conv2.bn.bias": 256,
  "conv2048256.conv.weight": 524288,
  "conv2048256.bn.weight": 256,
  "conv2048256.bn.bias": 256,
  "conv256256.conv.weight": 65536,
  "conv256256.bn.weight": 256,
  "conv256256.bn.bias": 256,
  "conv1024256.conv.weight": 262144,
  "conv1024256.bn.weight": 256,
  "conv1024256.bn.bias": 256,
  "conv512256.conv.weight": 131072,
  "conv512256.bn.weight": 256,
  "conv512256.bn.bias": 256,
  "conv32.conv.weight": 589824,
  "conv32.bn.weight": 256,
  "conv32.bn.bias": 256,
  "head4.0.conv.weight": 256,
  "head4.0.bn.weight": 1,
  "head4.0.bn.bias": 1,
  "head3.0.conv.weight": 256,
  "head3.0.bn.weight": 1,
  "head3.0.bn.bias": 1,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[03/20 10:51:57.369]: git:
  sha: N/A, status: clean, branch: N/A

[03/20 10:51:57.370]: Command: /media/test/run/ok/ED-Pose-master-6points-rtdetr-aifi-src-imploss-att-CLOA (5th copy)/main.py --output_dir logs/coco_r50 -c logs/coco_r50/config_cfg.py --options batch_size=4 epochs=60 lr_drop=55 num_body_points=6 backbone=resnet50 --dataset_file=coco --pretrain_model_path=logs/coco_r50/checkpoint_best_regular.pth --eval
[03/20 10:51:57.370]: Full config saved to logs/coco_r50/config_args_all.json
[03/20 10:51:57.370]: world size: 1
[03/20 10:51:57.370]: rank: 0
[03/20 10:51:57.370]: local_rank: 0
[03/20 10:51:57.371]: args: Namespace(config_file='logs/coco_r50/config_cfg.py', options={'batch_size': 4, 'epochs': 60, 'lr_drop': 55, 'num_body_points': 6, 'backbone': 'resnet50'}, dataset_file='coco', coco_path='/media/test/run/ED-Pose-master-6points/coco', remove_difficult=False, fix_size=False, output_dir='logs/coco_r50', note='', device='cuda', seed=42, resume='', pretrain_model_path='logs/coco_r50/checkpoint_best_regular.pth', finetune_ignore=None, start_epoch=0, eval=True, num_workers=0, test=False, debug=False, find_unused_params=False, save_results=False, save_log=False, world_size=1, dist_url='env://', rank=0, local_rank=0, amp=False, distributed=False, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_max_size=1333, data_aug_scales2_resize=[400, 500, 600], data_aug_scales2_crop=[384, 600], data_aug_scale_overlap=None, num_classes=2, lr=0.0001, param_dict_type='default', lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_linear_proj_names=['reference_points', 'sampling_offsets'], lr_linear_proj_mult=0.1, ddetr_lr_param=False, batch_size=4, weight_decay=0.0001, epochs=60, lr_drop=55, save_checkpoint_interval=100, clip_max_norm=0.1, onecyclelr=False, multi_step_lr=False, lr_drop_list=[33, 45], modelname='edpose', frozen_weights=None, backbone='resnet50', use_checkpoint=False, dilation=False, position_embedding='sine', pe_temperatureH=20, pe_temperatureW=20, return_interm_indices=[1, 2, 3], backbone_freeze_keywords=None, enc_layers=6, dec_layers=6, pre_norm=False, dim_feedforward=2048, hidden_dim=256, dropout=0.0, nheads=8, num_queries=900, query_dim=4, num_patterns=0, random_refpoints_xy=False, fix_refpoints_hw=-1, dec_layer_number=None, num_feature_levels=4, enc_n_points=4, dec_n_points=4, dln_xy_noise=0.2, dln_hw_noise=0.2, two_stage_type='standard', two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_learn_wh=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, rm_detach=None, num_select=50, transformer_activation='relu', batch_norm_type='FrozenBatchNorm2d', masks=False, aux_loss=True, set_cost_class=2.0, set_cost_bbox=5.0, set_cost_giou=2.0, set_cost_keypoints=10, set_cost_kpvis=0.0, set_cost_oks=4.0, cls_loss_coef=2.0, bbox_loss_coef=5.0, keypoints_loss_coef=14, oks_loss_coef=4.0, giou_loss_coef=2.0, enc_loss_coef=1.0, interm_loss_coef=1.0, no_interm_box_loss=False, focal_alpha=0.25, rm_self_attn_layers=None, indices_idx_list=[1, 2, 3, 4, 5, 6, 7], decoder_sa_type='sa', matcher_type='HungarianMatcher', decoder_module_seq=['sa', 'ca', 'ffn'], nms_iou_threshold=-1, dec_pred_bbox_embed_share=False, dec_pred_class_embed_share=False, dec_pred_pose_embed_share=False, use_dn=True, dn_number=100, dn_box_noise_scale=0.4, dn_label_noise_ratio=0.5, embed_init_tgt=False, dn_label_coef=0.3, dn_bbox_coef=0.5, dn_batch_gt_fuse=False, dn_attn_mask_type_list=['match2dn', 'dn2dn', 'group2group'], dn_labelbook_size=100, match_unstable_error=False, use_ema=True, ema_decay=0.9997, ema_epoch=0, cls_no_bias=False, num_body_points=6, num_group=100, num_box_decoder_layers=2, no_mmpose_keypoint_evaluator=True, strong_aug=False)

[03/20 10:51:58.318]: number of params:53089445
[03/20 10:51:58.320]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.hw.weight": 12,
  "transformer.decoder.keypoint_embed.weight": 1536,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.1.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.1.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.1.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.1.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.2.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.2.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.2.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.2.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.3.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.3.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.3.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.3.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.4.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.4.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.4.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.4.layers.2.bias": 4,
  "transformer.decoder.bbox_embed.5.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.5.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.5.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.5.layers.2.bias": 4,
  "transformer.decoder.pose_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_embed.0.layers.2.bias": 2,
  "transformer.decoder.pose_embed.1.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.0.bias": 256,
  "transformer.decoder.pose_embed.1.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.1.layers.1.bias": 256,
  "transformer.decoder.pose_embed.1.layers.2.weight": 512,
  "transformer.decoder.pose_embed.1.layers.2.bias": 2,
  "transformer.decoder.pose_embed.2.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.0.bias": 256,
  "transformer.decoder.pose_embed.2.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.2.layers.1.bias": 256,
  "transformer.decoder.pose_embed.2.layers.2.weight": 512,
  "transformer.decoder.pose_embed.2.layers.2.bias": 2,
  "transformer.decoder.pose_embed.3.layers.0.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.0.bias": 256,
  "transformer.decoder.pose_embed.3.layers.1.weight": 65536,
  "transformer.decoder.pose_embed.3.layers.1.bias": 256,
  "transformer.decoder.pose_embed.3.layers.2.weight": 512,
  "transformer.decoder.pose_embed.3.layers.2.bias": 2,
  "transformer.decoder.pose_hw_embed.0.layers.0.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.0.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.1.weight": 65536,
  "transformer.decoder.pose_hw_embed.0.layers.1.bias": 256,
  "transformer.decoder.pose_hw_embed.0.layers.2.weight": 512,
  "transformer.decoder.pose_hw_embed.0.layers.2.bias": 2,
  "transformer.decoder.class_embed.0.weight": 512,
  "transformer.decoder.class_embed.0.bias": 2,
  "transformer.decoder.class_embed.1.weight": 512,
  "transformer.decoder.class_embed.1.bias": 2,
  "transformer.decoder.class_embed.2.weight": 512,
  "transformer.decoder.class_embed.2.bias": 2,
  "transformer.decoder.class_embed.3.weight": 512,
  "transformer.decoder.class_embed.3.bias": 2,
  "transformer.decoder.class_embed.4.weight": 512,
  "transformer.decoder.class_embed.4.bias": 2,
  "transformer.decoder.class_embed.5.weight": 512,
  "transformer.decoder.class_embed.5.bias": 2,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 512,
  "transformer.enc_out_class_embed.bias": 2,
  "label_enc.weight": 25856,
  "input_projj.0.0.weight": 65536,
  "input_projj.0.1.weight": 256,
  "input_projj.0.1.bias": 256,
  "input_projj.1.0.weight": 65536,
  "input_projj.1.1.weight": 256,
  "input_projj.1.1.bias": 256,
  "input_projj.2.0.weight": 65536,
  "input_projj.2.1.weight": 256,
  "input_projj.2.1.bias": 256,
  "mlca.conv_bn_relu_prm_1.conv.weight": 589824,
  "mlca.conv_bn_relu_prm_1.conv.bias": 256,
  "mlca.conv_bn_relu_prm_1.bn.weight": 256,
  "mlca.conv_bn_relu_prm_1.bn.bias": 256,
  "mlca.conv_bn_relu_prm_2_1.conv.weight": 65536,
  "mlca.conv_bn_relu_prm_2_1.conv.bias": 256,
  "mlca.conv_bn_relu_prm_2_1.bn.weight": 256,
  "mlca.conv_bn_relu_prm_2_1.bn.bias": 256,
  "mlca.conv_bn_relu_prm_2_2.conv.weight": 65536,
  "mlca.conv_bn_relu_prm_2_2.conv.bias": 256,
  "mlca.conv_bn_relu_prm_2_2.bn.weight": 256,
  "mlca.conv_bn_relu_prm_2_2.bn.bias": 256,
  "mlca.conv_bn_relu_prm_3_1.conv.weight": 65536,
  "mlca.conv_bn_relu_prm_3_1.conv.bias": 256,
  "mlca.conv_bn_relu_prm_3_1.bn.weight": 256,
  "mlca.conv_bn_relu_prm_3_1.bn.bias": 256,
  "mlca.conv_bn_relu_prm_3_2.conv.weight": 20736,
  "mlca.conv_bn_relu_prm_3_2.conv.bias": 256,
  "mlca.conv_bn_relu_prm_3_2.bn.weight": 256,
  "mlca.conv_bn_relu_prm_3_2.bn.bias": 256,
  "mlca.ca.ca.fc0.weight": 4096,
  "mlca.ca.ca.fc0.bias": 16,
  "mlca.ca.ca.bn0.weight": 16,
  "mlca.ca.ca.bn0.bias": 16,
  "mlca.ca.ca.fc1.weight": 256,
  "mlca.ca.ca.fc1.bias": 16,
  "mlca.ca.ca.bn1.weight": 16,
  "mlca.ca.ca.bn1.bias": 16,
  "mlca.ca.ca.fc2.weight": 256,
  "mlca.ca.ca.fc2.bias": 16,
  "mlca.ca.ca.bn2.weight": 16,
  "mlca.ca.ca.bn2.bias": 16,
  "mlca.ca.ca.last_fc.weight": 4096,
  "mlca.ca.ca.last_fc.bias": 256,
  "mlca.sa.sa.conv_reduce1.weight": 4096,
  "mlca.sa.sa.conv_reduce1.bias": 16,
  "mlca.sa.sa.bn_reduce1.weight": 16,
  "mlca.sa.sa.bn_reduce1.bias": 16,
  "mlca.sa.sa.conv_0.weight": 2304,
  "mlca.sa.sa.conv_0.bias": 16,
  "mlca.sa.sa.bn_0.weight": 16,
  "mlca.sa.sa.bn_0.bias": 16,
  "mlca.sa.sa.conv_1.weight": 2304,
  "mlca.sa.sa.conv_1.bias": 16,
  "mlca.sa.sa.bn_1.weight": 16,
  "mlca.sa.sa.bn_1.bias": 16,
  "mlca.sa.sa.conv_2.weight": 2304,
  "mlca.sa.sa.conv_2.bias": 16,
  "mlca.sa.sa.bn_2.weight": 16,
  "mlca.sa.sa.bn_2.bias": 16,
  "mlca.sa.sa.last_conv.weight": 16,
  "mlca.sa.sa.last_conv.bias": 1,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "AIFI.ma.in_proj_weight": 196608,
  "AIFI.ma.in_proj_bias": 768,
  "AIFI.ma.out_proj.weight": 65536,
  "AIFI.ma.out_proj.bias": 256,
  "AIFI.fc1.weight": 131072,
  "AIFI.fc1.bias": 512,
  "AIFI.fc2.weight": 131072,
  "AIFI.fc2.bias": 256,
  "AIFI.norm1.weight": 256,
  "AIFI.norm1.bias": 256,
  "AIFI.norm2.weight": 256,
  "AIFI.norm2.bias": 256,
  "Repc3.cv1.conv.weight": 131072,
  "Repc3.cv1.bn.weight": 256,
  "Repc3.cv1.bn.bias": 256,
  "Repc3.cv2.conv.weight": 131072,
  "Repc3.cv2.bn.weight": 256,
  "Repc3.cv2.bn.bias": 256,
  "Repc3.m.0.conv1.conv.weight": 589824,
  "Repc3.m.0.conv1.bn.weight": 256,
  "Repc3.m.0.conv1.bn.bias": 256,
  "Repc3.m.0.conv2.conv.weight": 65536,
  "Repc3.m.0.conv2.bn.weight": 256,
  "Repc3.m.0.conv2.bn.bias": 256,
  "Repc3.m.1.conv1.conv.weight": 589824,
  "Repc3.m.1.conv1.bn.weight": 256,
  "Repc3.m.1.conv1.bn.bias": 256,
  "Repc3.m.1.conv2.conv.weight": 65536,
  "Repc3.m.1.conv2.bn.weight": 256,
  "Repc3.m.1.conv2.bn.bias": 256,
  "Repc3.m.2.conv1.conv.weight": 589824,
  "Repc3.m.2.conv1.bn.weight": 256,
  "Repc3.m.2.conv1.bn.bias": 256,
  "Repc3.m.2.conv2.conv.weight": 65536,
  "Repc3.m.2.conv2.bn.weight": 256,
  "Repc3.m.2.conv2.bn.bias": 256,
  "conv2048256.conv.weight": 524288,
  "conv2048256.bn.weight": 256,
  "conv2048256.bn.bias": 256,
  "conv256256.conv.weight": 65536,
  "conv256256.bn.weight": 256,
  "conv256256.bn.bias": 256,
  "conv1024256.conv.weight": 262144,
  "conv1024256.bn.weight": 256,
  "conv1024256.bn.bias": 256,
  "conv512256.conv.weight": 131072,
  "conv512256.bn.weight": 256,
  "conv512256.bn.bias": 256,
  "conv32.conv.weight": 589824,
  "conv32.bn.weight": 256,
  "conv32.bn.bias": 256,
  "head4.0.conv.weight": 256,
  "head4.0.bn.weight": 1,
  "head4.0.bn.bias": 1,
  "head3.0.conv.weight": 256,
  "head3.0.bn.weight": 1,
  "head3.0.bn.bias": 1,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
